---
layout: post
title: Approximate Message Passing (AMP) Algorithm
description: Approximate Message Passing (AMP) algorithm is to solve under-determined problem, that is, to recover sparse signals from few samples. I will take sparse channel estimation as an example to describe how to implement AMP algorithm and compare it with the well-known OMP (orthogonal matching pursuit) algorithm.
category: blog
---
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

Approximate Message Passing (AMP) algorithm is to solve under-determined problems, that is, to recover sparse signals from few samples. I will take sparse channel estimation as an example to describe how to implement AMP algorithm and compare it with the well-known OMP (orthogonal matching pursuit) algorithm.

## Under-determined Problem (Example: Sparse Channel Estimation)
Let us denote the channel information vector as \\(\boldsymbol{h}\\), and sparse channel means that most of elements in \\(\boldsymbol{h}\\) are zero. Consider transmitting pilot signals \\(\boldsymbol{x}\\) through a sparse channel, and the received samples \\(\boldsymbol{y}\\) vector is the convolution betwwen signals \\(\boldsymbol{x}\\) and the channel information vector \\(\boldsymbol{h}\\). The equation of \\(\boldsymbol{y}\\) is expressed as following:

$$
\begin{bmatrix}
y_{1}\\
y_{2}\\
y_{3}\\
\vdots\\
y_{n}
\end{bmatrix}=
\begin{bmatrix}
x_{N} & x_{N-1} & x_{N-2} & \ldots & x_1 \\
x_{1} & x_{N} & x_{N-1} & \ldots & x_2\\
x_{2} & x_{1} & x_{N} & \ldots & x_3 \\
\vdots & \vdots & \vdots & \ddots & \vdots\\
x_{N-1} & x_{n-2} & x_{n-3} & \ldots & x_{n}
\end{bmatrix}\cdot
\begin{bmatrix}
h_{1}\\
h_{2}\\
h_{3} \\
\vdots\\
h_{N}
\end{bmatrix}
+ \boldsymbol{w}
$$

that is,

$$\boldsymbol{y}=\mathbf{A}\cdot\boldsymbol{h} +\boldsymbol{w}$$

where \\(\boldsymbol{w}\\) is assumed to be Gaussian noise vector and \\(\mathbf{A} (n\times N)\\) is called sening matrix, composed of shift pilot sigals. Note that the size of \\(\boldsymbol{y}\\) is \\(n \times 1\\), and the size of \\(\boldsymbol{x}\\) and \\(\boldsymbol{h}\\) are \\(N \times 1\\).

To find the accurate solution of channel information vector \\(h\\), we may think that it is requirable that we have condition \\(n \geq N\\) based on our knowledge of linear algebra. However, in this scenario, our focus is to have good estimation of the channel while we can still have high data rate, which means that we would like to estimate the channel with received samples \\(\boldsymbol{y}\\) as fewer as possible. Therefore, we try to find a good estimation of vector \\(\boldsymbol{h}\\) with condition that \\( n < N\\), and this is called under-determined problem.

## AMP Algorithm
The sparse channel estimation example above has a important feature that vector \\( \boldsymbol{h}\\) is sparse. Here, AMP algorithm is to solve under-determined problems given that the vector we want to estimate is sparse. AMP is derived from the graphical model theory and message passing algorithm, see reference [1], and it simplifies the procedures of message passing that requires tracking of \\( 2nN\\) messages. It works iteratively with vector \\( \boldsymbol{y}\\) and matrix \\( \mathbf{A}\\) as inputs. Estimation result denoted by \\( \hat{\boldsymbol{h}}\\) will converge after several iterations with mean square error (MSE) smaller than \\( 10^{-4}\\). In detail, AMP has following steps:

1. Intialization: \\(\boldsymbol{z}^0 = \boldsymbol{y}, \boldsymbol{\theta}^0 = \boldsymbol{0}, t=0\\)
2. _while_ \\( t<I\\) _do_
3. &nbsp; &nbsp; \\(\hat{\boldsymbol{\theta}}^{t+1} = \eta(\boldsymbol{A}^{T}\boldsymbol{z}^t+\boldsymbol{\theta}^t;\hat{\tau}^t)\\)
4. &nbsp; &nbsp; \\(\boldsymbol{z}^t = \boldsymbol{y}-\boldsymbol{A}\hat{\boldsymbol{\theta}}^t+\frac{1}{\delta}\boldsymbol{z}^{t-1}<\eta'(\boldsymbol{A}^{T}\boldsymbol{z}^{t-1}+\hat{\boldsymbol{\theta}}^{t-1};\hat{\tau}^{t-1})>\\)
5. &nbsp; &nbsp; \\( t = t+1\\)
6.  &nbsp; &nbsp; \\(\hat{\tau}^{t+1} = \sqrt{N_0+\left(\frac{\hat{\tau}^{t-1}}{\delta}<\eta'(\boldsymbol{A}^{T}\boldsymbol{z}^{t-1}+\hat{\boldsymbol{\theta}}^{t-1};\hat{\tau}^{t-1})>\right)^2}\\)
7. end while

where,
$$
\begin{itemize}
 \item I
\end{itemize}
$$


## Reference
1. David L Donoho, Arian Maleki, and Andrea Montanari. How to design message passing algorithms for compressed sensing. preprint, 2011.


